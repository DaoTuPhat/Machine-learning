{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(folder_path, img_size=(224, 224)):\n",
    "    images, labels = [], []\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "        label = 0 if subfolder.lower() == \"good\" else 1\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            try:\n",
    "                img_path = os.path.join(subfolder_path, filename)\n",
    "                img = load_img(img_path, target_size=img_size)\n",
    "                img = img_to_array(img)\n",
    "                img = preprocess_input(img)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image: {img_path}, error: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def get_test_image_paths(test_folder):\n",
    "    paths = []\n",
    "    for subfolder in os.listdir(test_folder):\n",
    "        sub_path = os.path.join(test_folder, subfolder)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "        paths += sorted(glob.glob(os.path.join(sub_path, '*.png')))\n",
    "    return paths\n",
    "\n",
    "def load_ground_truth_masks(gt_mask_folder, test_image_paths, target_size=(28, 28)):\n",
    "    masks = []\n",
    "    for path in test_image_paths:\n",
    "        cls = os.path.basename(os.path.dirname(path))\n",
    "        fname = os.path.basename(path)\n",
    "\n",
    "        if cls == 'good':\n",
    "            mask = np.zeros(target_size, dtype=np.uint8)\n",
    "        else:\n",
    "            defect_type = cls\n",
    "            name, ext = os.path.splitext(fname)\n",
    "            mask_name = name + '_mask' + ext\n",
    "            mask_path = os.path.join(gt_mask_folder, defect_type, mask_name)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = imread(mask_path, as_gray=True)\n",
    "                mask = resize(mask, target_size, anti_aliasing=False, preserve_range=True)\n",
    "                mask = (mask > 0.5).astype(np.uint8)\n",
    "            else:\n",
    "                mask = np.zeros(target_size, dtype=np.uint8)\n",
    "        masks.append(mask)\n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extractor(input_shape=(224, 224, 3)):\n",
    "    base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base.trainable = False\n",
    "    layer_names = ['conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "    outputs = [base.get_layer(name).output for name in layer_names]\n",
    "    model = tf.keras.Model(inputs=base.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def extract_patch_features(images, model):\n",
    "    features_list = model.predict(images, verbose=0)\n",
    "    resized_features = [\n",
    "        tf.image.resize(f, size=(28, 28)).numpy()\n",
    "        for f in features_list\n",
    "    ]\n",
    "    combined = np.concatenate(resized_features, axis=-1)\n",
    "    N, H, W, C = combined.shape\n",
    "    patches = combined.reshape(N, H * W, C)\n",
    "    return patches, H, W\n",
    "\n",
    "\n",
    "def compute_anomaly_maps(memory_bank, test_patches, H, W, k=1):\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='euclidean', n_jobs=-1)\n",
    "    nn.fit(memory_bank)\n",
    "    maps = []\n",
    "    for patch in tqdm(test_patches, desc=\"Computing anomaly maps\"):\n",
    "        dist, _ = nn.kneighbors(patch)\n",
    "        scores = dist.mean(axis=1).reshape(H, W)\n",
    "        maps.append(scores)\n",
    "    return np.array(maps)\n",
    "\n",
    "\n",
    "def compute_auprc(y_true, y_score):\n",
    "    return average_precision_score(y_true.flatten(), y_score.flatten())\n",
    "\n",
    "\n",
    "def run_patchcore(product):\n",
    "    train_dir = f'data/{product}/train'\n",
    "    test_dir = f'data/{product}/test'\n",
    "    gt_dir = f'data/{product}/ground_truth'\n",
    "\n",
    "    train_imgs, _ = process_images(train_dir)\n",
    "    test_imgs, _ = process_images(test_dir)\n",
    "    test_paths = get_test_image_paths(test_dir)\n",
    "\n",
    "    model = get_feature_extractor()\n",
    "    train_patches, H, W = extract_patch_features(train_imgs, model)\n",
    "    test_patches, _, _ = extract_patch_features(test_imgs, model)\n",
    "\n",
    "    memory_bank = train_patches.reshape(-1, train_patches.shape[-1])\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    memory_bank_processed = pca.fit_transform(memory_bank)\n",
    "    test_patches_processed = pca.transform(test_patches.reshape(-1, test_patches.shape[-1]))\n",
    "\n",
    "    test_patches_processed_reshaped = test_patches_processed.reshape(test_imgs.shape[0], H * W, -1)\n",
    "\n",
    "    maps = compute_anomaly_maps(\n",
    "        memory_bank_processed,\n",
    "        test_patches_processed_reshaped,\n",
    "        H, W,\n",
    "        k=1\n",
    "    )\n",
    "\n",
    "    gt_masks = load_ground_truth_masks(gt_dir, test_paths, (H, W))\n",
    "    score = compute_auprc(gt_masks, maps)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 117/117 [02:20<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carpet         : AUPRC = 0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 78/78 [01:01<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid           : AUPRC = 0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 124/124 [01:59<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leather        : AUPRC = 0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 117/117 [02:10<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile           : AUPRC = 0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 79/79 [01:32<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wood           : AUPRC = 0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 83/83 [00:35<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle         : AUPRC = 0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 150/150 [02:49<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cable          : AUPRC = 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 132/132 [01:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capsule        : AUPRC = 0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 110/110 [02:41<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hazelnut       : AUPRC = 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 115/115 [01:18<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal_nut      : AUPRC = 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 167/167 [01:31<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pill           : AUPRC = 0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 160/160 [02:27<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screw          : AUPRC = 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 42/42 [00:04<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toothbrush     : AUPRC = 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transistor     : AUPRC = 0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing anomaly maps: 100%|██████████| 151/151 [00:47<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipper         : AUPRC = 0.643\n",
      "Average Pixel-level AUPRC across all products: 0.545\n"
     ]
    }
   ],
   "source": [
    "products = ['carpet', 'grid', 'leather', 'tile', 'wood', 'bottle', 'cable', 'capsule', 'hazelnut',\n",
    "            'metal_nut', 'pill', 'screw', 'toothbrush', 'transistor', 'zipper']\n",
    "\n",
    "all_products_auprc = {}\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "for prod in products:\n",
    "    auprc_score = run_patchcore(prod)\n",
    "    all_products_auprc[prod] = auprc_score\n",
    "    print(f\"{prod:<15}: AUPRC = {auprc_score:.3f}\")\n",
    "\n",
    "if all_products_auprc:\n",
    "    average_auprc = np.mean(list(all_products_auprc.values()))\n",
    "    print(f\"Average Pixel-level AUPRC across all products: {average_auprc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
